# Luminance Domain Guided Low-light Image Enhancement 
In low-light conditions, images have poor contrast and noise due to lack of exposure, making it difficult to work with them. In fact, low-light images also have uneven brightness, such as nightlight, backlight and shadow occlusion. A common drawback of existing low-light enhancement methods is that they tend to increase the overall image brightness, which can result in overexposure of areas that were not originally low-light. In fact, dark areas should be enhanced while overexposed areas should be suppressed. To address this problem, this paper proposes a novel Uneven Dark Vision Network (UDVN), which consists of two sub-networks. The Luminance Domain Network (LDN) uses the Direction-aware Spatial Context (DSC) and Feature Enhancement Module (FEM) to segment different light regions in the image and output the luminance domain mask. Guided by the luminance domain mask, the Light Enhancement Network (LEN) uses our innovative Cross-Domain Transformation Residual (CDTR) block to adaptively illuminate different illumination regions, while we introduce a new region loss function to constrain the LEN to better enhance the quality of the different illumination regions. Additionally, we develop  low-light synthesis dataset (UDL) that includes more diverse illumination states and is larger than existing datasets. Extensive experiments on several benchmark datasets show that the proposed method is very competitive with state-of-the-art methods. Particularly when dealing with uneven low-light images, it has significant advantages in terms of illumination recovery and detail preservation.

![Fig 2](https://user-images.githubusercontent.com/66294411/196342227-d3aa9f4f-2754-4244-b412-2a23ae46a19c.png)

Anyone can access the UDL dataset via https://ln5.sync.com/dl/c51f8c480/uih7d8gc-zdbwhxvn-j8xah678-98k832ns
